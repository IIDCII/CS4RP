{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune Test \n",
    "Test for fine tuning language models using LoRa on Bath's Hex Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up on Hex Cloud\n",
    "## Getting Access\n",
    "- if you don't have permission to a cluster/machine, email Tom Haines\n",
    "- open a terminal and sign in via ssh and input your password\n",
    "    ```\n",
    "    ssh uniusername@clustername.cs.bath.ac.uk\n",
    "    ```\n",
    "    If the following doesn't work, make sure that you're in Bath and if not, connect to the university's VPN or any other VPN\n",
    "- once you're in you want to navigate to the the fast/er folders. You want to do all of your projects there because they're the least laggy and you have up to 3.8T of storage for your project (varies)\n",
    "    <img src=\"assets/s1.png\" width = \"300\">\n",
    "- the following is an example of how you would access the fast/faster project files\n",
    "- check which of the files has the most space and create a folder with your username\n",
    "- do not put any confidential information or API keys within this folder. If you want to use that, put that in your home folder and call them from your project folder\n",
    "\n",
    "## Getting Access via VsCode\n",
    "- if you want to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this based on the server usage\n",
    "# need to run this first to make sure that it runs on the correct GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/faster2/dc903/CS4RP/fttenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, TrainingArguments, pipeline, BitsAndBytesConfig\n",
    "from huggingface_hub import login, snapshot_download, hf_hub_download\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "import torch.nn as nn\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check VRAM\n",
    "# if not using Cheery, you will need to change this\n",
    "def check_vram():\n",
    "    # Initialize NVIDIA management library\n",
    "    pynvml.nvmlInit()\n",
    "\n",
    "    # Get a handle for each GPU device\n",
    "    handle_list = [pynvml.nvmlDeviceGetHandleByIndex(i) for i in range(pynvml.nvmlDeviceGetCount())]\n",
    "\n",
    "    info_used = []\n",
    "    points = [0,1,2,3,4,5,6,7]\n",
    "    max_vram = 24\n",
    "\n",
    "    # Iterate over all GPU devices and print VRAM usage\n",
    "    for handle in handle_list:\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        info_used.append( (info.used//1024**2)/1000)\n",
    "\n",
    "    print (info_used)\n",
    "\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.ylim(0,max_vram)\n",
    "    plt.bar(points, info_used)\n",
    "    plt.plot()\n",
    "    pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT RUN THIS CODE BLOCK IF 'llama-2-7b-hf' IS IN YOUR DIRECTORY\n",
    "\"\"\"\n",
    "\n",
    "# getting the authorisation from huggingface to use the model (in this case llama 2 7b )\n",
    "access_key = open('hf_ak.txt','r').read()\n",
    "login(token = access_key)\n",
    "\n",
    "# Download model files. If it's in the project directory, there's no need to run this again\n",
    "# use df -H in the terminal to check and see if there's enough space to download the model\n",
    "# this process will take a long time\n",
    "# will save the model in the directory specified\n",
    "model_path = snapshot_download(\"meta-llama/Llama-2-7b-hf\", local_dir=\"./llama-2-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do not run any of this is if llama-2-7b-hf is filled\n",
    "- You'll need to convert them to the huggingface Transformers format using the conversion script `convert_llama_weights_to_hf.py`. \n",
    "- Obviously, hf stands for huggingface. Maybe with the hf version, the conversion wouldn't be needed\n",
    "- to run this, run the following\n",
    "\n",
    "```\n",
    "python convert_llama_weights_to_hf.py \\\n",
    "    --input_dir /llama-2-7b --model_size 7B --output_dir /llama-2-7b-hf\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.079, 5.791, 0.415, 4.677, 0.415, 0.415, 0.418, 0.418]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilization.gpu [%]\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n"
     ]
    }
   ],
   "source": [
    "# each GPU util\n",
    "!nvidia-smi --query-gpu=utilization.gpu --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and tokenizer names\n",
    "base_model_name = \"llama-2-7b-hf\"\n",
    "new_model_name = \"llama-2-7b-enhanced\" #You can give your own name for fine tuned model\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "# resolve device_map_auto issue\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.079, 5.791, 0.415, 4.677, 0.415, 0.415, 13.479, 13.479]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3919"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the following code if you want to unload the VRAM. You may have to run this more than once to unload\n",
    "# Remove model from GPU. Add any more variables that can get loaded on\n",
    "\n",
    "# uncomment this if not deleted\n",
    "# del base_model\n",
    "# del llama_tokenizer\n",
    "\n",
    "# Clear any remaining CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "[1.079, 5.791, 0.415, 4.677, 0.415, 0.415, 0.625, 0.625]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAADFCAYAAAAxI3fRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAR90lEQVR4nO3df2zU9eHH8dfZ2oNg72qR/rhxLSAgTkbH+NF1oIvSUBrCZPPXCMvKZDOSYwM7wmyyWZctHpuZQTZsRTeQLIg/khZ/RLBUPbKsVcE0gy12FOuow5aNrXdtFw7S+3z/cN53J7322t710zc8H8k78fPjPp+X1eR1n/u87z4Oy7IsAQBgqKvsDgAAwGhQZAAAo1FkAACjUWQAAKNRZAAAo1FkAACjUWQAAKOl2x3gsyKRiM6cOaPMzEw5HA674wAAbGJZlnp6euTxeHTVVfGvu8ZdkZ05c0Zer9fuGACAcaKjo0NTp06Nu33cFVlmZqakT4K7XC6b0wAA7BIKheT1eqO9EM+4K7JPP050uVwUGQBgyNtMTPYAABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABhtWEXm9/u1aNEiZWZmKicnR6tXr1Zra2vMPufPn5fP59PkyZN1zTXX6I477lBXV1dSQwMA8KlhFVkgEJDP51Nzc7MaGhp08eJFLV++XH19fdF9HnjgAb388st64YUXFAgEdObMGX3jG99IenAAACTJYVmWNdIX/+Mf/1BOTo4CgYBuueUWBYNBTZkyRfv27dOdd94pSXr//fd14403qqmpSV/+8peHPGYoFJLb7VYwGJTL5RppNACA4RLtg1HdIwsGg5Kk7OxsSdKxY8d08eJFlZaWRveZM2eOCgoK1NTUNOAxwuGwQqFQzAAAIFEjLrJIJKLNmzdryZIlmjt3riSps7NTGRkZysrKitk3NzdXnZ2dAx7H7/fL7XZHh9frHWkkAMAVaMRF5vP5dOLECe3fv39UAaqqqhQMBqOjo6NjVMcDAFxZ0kfyoo0bN+qVV17RkSNHNHXq1Oj6vLw8XbhwQd3d3TFXZV1dXcrLyxvwWE6nU06ncyQxAAAY3hWZZVnauHGj6urq9MYbb2j69Okx2xcsWKCrr75ajY2N0XWtra06ffq0SkpKkpMYAID/MawrMp/Pp3379unAgQPKzMyM3vdyu92aOHGi3G631q9fr8rKSmVnZ8vlcun73/++SkpKEpqxCADAcA1r+r3D4Rhw/e7du7Vu3TpJn3wh+oc//KGeffZZhcNhlZWV6Yknnoj70eJnMf0eACAl3gej+h5ZKlBkAABpjL5HBgCA3SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNGGXWRHjhzRqlWr5PF45HA4VF9fH7N93bp1cjgcMWPFihXJygsAQIxhF1lfX5+Kioq0c+fOuPusWLFCH3/8cXQ8++yzowoJAEA86cN9QXl5ucrLywfdx+l0Ki8vb8ShAABIVErukb311lvKycnRDTfcoA0bNujcuXNx9w2HwwqFQjEDAIBEJb3IVqxYob1796qxsVG/+MUvFAgEVF5erv7+/gH39/v9crvd0eH1epMdCQBwGXNYlmWN+MUOh+rq6rR69eq4+3zwwQe6/vrrdfjwYS1btuyS7eFwWOFwOLocCoXk9XoVDAblcrlGGg0AYLhQKCS32z1kH6R8+v2MGTN03XXXqa2tbcDtTqdTLpcrZgAAkKiUF9lHH32kc+fOKT8/P9WnAgBcgYY9a7G3tzfm6qq9vV0tLS3Kzs5Wdna2fvrTn+qOO+5QXl6eTp06pa1bt2rmzJkqKytLanAAAKQRFNnRo0d16623RpcrKyslSRUVFaqpqdGf/vQnPfPMM+ru7pbH49Hy5cv1s5/9TE6nM3mpAQD4r1FN9kiFRG/uAQAub+NmsgcAAKlEkQEAjEaRAQCMRpEBAIxGkQEAjEaRAQCMRpEBAIxGkQEAjEaRAQCMRpEBAIxGkQEAjEaRAQCMRpEBAIxGkQEAjEaRAQCMRpEBAIxGkQEAjEaRAQCMRpEBAIxGkQEAjEaRAQCMNuwiO3LkiFatWiWPxyOHw6H6+vqY7ZZl6aGHHlJ+fr4mTpyo0tJSnTx5Mll5AQCIMewi6+vrU1FRkXbu3Dng9l/+8pfasWOHamtr9fbbb2vSpEkqKyvT+fPnRx0WAIDPSh/uC8rLy1VeXj7gNsuytH37dv34xz/W7bffLknau3evcnNzVV9fr29+85ujSwsAwGck9R5Ze3u7Ojs7VVpaGl3ndrtVXFyspqamAV8TDocVCoViBgAAiUpqkXV2dkqScnNzY9bn5uZGt32W3++X2+2ODq/Xm8xIAIDLnO2zFquqqhQMBqOjo6PD7kgAAIMktcjy8vIkSV1dXTHru7q6ots+y+l0yuVyxQwAABKV1CKbPn268vLy1NjYGF0XCoX09ttvq6SkJJmnAgBA0ghmLfb29qqtrS263N7erpaWFmVnZ6ugoECbN2/Wz3/+c82aNUvTp0/XT37yE3k8Hq1evTqZuQEAkDSCIjt69KhuvfXW6HJlZaUkqaKiQnv27NHWrVvV19en++67T93d3Vq6dKkOHjyoCRMmJC81AAD/5bAsy7I7xP8KhUJyu90KBoPcLwOAK1iifWD7rEUAAEaDIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGI0iAwAYjSIDABiNIgMAGC3d7gCINe3BV+2OEOPDbSvtjgAAg0r6FdnDDz8sh8MRM+bMmZPs0wAAIClFV2Q33XSTDh8+/P8nSefCDwCQGilpmPT0dOXl5aXi0AAAxEjJZI+TJ0/K4/FoxowZWrt2rU6fPh1333A4rFAoFDMAAEhU0ousuLhYe/bs0cGDB1VTU6P29nbdfPPN6unpGXB/v98vt9sdHV6vN9mRAACXMYdlWVYqT9Dd3a3CwkI99thjWr9+/SXbw+GwwuFwdDkUCsnr9SoYDMrlcqUy2rjErEUA+EQoFJLb7R6yD1I+CyMrK0uzZ89WW1vbgNudTqecTmeqYwAxxtsbBok3DcBIpfwL0b29vTp16pTy8/NTfSoAwBUo6UW2ZcsWBQIBffjhh/rjH/+or3/960pLS9OaNWuSfSoAAJL/0eJHH32kNWvW6Ny5c5oyZYqWLl2q5uZmTZkyJdmnAgAg+UW2f//+ZB8SAIC4+NFgAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0SgyAIDRKDIAgNEoMgCA0dLtDpBK0x581e4IMT7cttLuCABw2eGKDABgNIoMAGC0y/qjRQAYCRNvS5iYOVlSdkW2c+dOTZs2TRMmTFBxcbHeeeedVJ0KAHAFS8kV2XPPPafKykrV1taquLhY27dvV1lZmVpbW5WTk5OKU8JGV/I7wbFm4t/axMwwS0qK7LHHHtP3vvc9fec735Ek1dbW6tVXX9Xvfvc7PfjggzH7hsNhhcPh6HIwGJQkhUKhUeeIhP8z6mMkUyL/TmQePRMzS2bmJvPYuFwzJ3oMy7IG39FKsnA4bKWlpVl1dXUx67/97W9bX/va1y7Zv7q62pLEYDAYDMaAo6OjY9DeSfoV2T//+U/19/crNzc3Zn1ubq7ef//9S/avqqpSZWVldDkSiehf//qXJk+eLIfDkex4wxYKheT1etXR0SGXy2V3nISQeeyYmJvMY4PMo2dZlnp6euTxeAbdz/ZZi06nU06nM2ZdVlaWPWEG4XK5xsV/2OEg89gxMTeZxwaZR8ftdg+5T9JnLV533XVKS0tTV1dXzPquri7l5eUl+3QAgCtc0ossIyNDCxYsUGNjY3RdJBJRY2OjSkpKkn06AMAVLiUfLVZWVqqiokILFy7U4sWLtX37dvX19UVnMZrE6XSqurr6ko8/xzMyjx0Tc5N5bJB57Dgsa6h5jSPzm9/8Ro8++qg6Ozv1xS9+UTt27FBxcXEqTgUAuIKlrMgAABgL/GgwAMBoFBkAwGgUGQDAaBQZAMBoFNkQTHoczZEjR7Rq1Sp5PB45HA7V19fbHWlIfr9fixYtUmZmpnJycrR69Wq1trbaHWtQNTU1mjdvXvTXD0pKSvTaa6/ZHWtYtm3bJofDoc2bN9sdZVAPP/ywHA5HzJgzZ47dsYb097//Xd/61rc0efJkTZw4UV/4whd09OhRu2PFNW3atEv+zg6HQz6fz+5oCaHIBvHp42iqq6v13nvvqaioSGVlZTp79qzd0QbU19enoqIi7dy50+4oCQsEAvL5fGpublZDQ4MuXryo5cuXq6+vz+5ocU2dOlXbtm3TsWPHdPToUd122226/fbb9ec//9nuaAl599139eSTT2revHl2R0nITTfdpI8//jg6/vCHP9gdaVD//ve/tWTJEl199dV67bXX9Je//EW/+tWvdO2119odLa5333035m/c0NAgSbrrrrtsTpagJP3o/WVp8eLFls/niy739/dbHo/H8vv9NqZKjKRLnkBggrNnz1qSrEAgYHeUYbn22mutp59+2u4YQ+rp6bFmzZplNTQ0WF/96letTZs22R1pUNXV1VZRUZHdMYblRz/6kbV06VK7Y4zKpk2brOuvv96KRCJ2R0kIV2RxXLhwQceOHVNpaWl03VVXXaXS0lI1NTXZmOzy9unz6LKzs21Okpj+/n7t379ffX19RvwEm8/n08qVK2P+vx7vTp48KY/HoxkzZmjt2rU6ffq03ZEG9dJLL2nhwoW66667lJOTo/nz5+upp56yO1bCLly4oN///ve69957x8UTSBJBkcUx2ONoOjs7bUp1eYtEItq8ebOWLFmiuXPn2h1nUMePH9c111wjp9Op+++/X3V1dfr85z9vd6xB7d+/X++99578fr/dURJWXFysPXv26ODBg6qpqVF7e7tuvvlm9fT02B0trg8++EA1NTWaNWuWDh06pA0bNugHP/iBnnnmGbujJaS+vl7d3d1at26d3VESZvtjXIBP+Xw+nThxYtzfA5GkG264QS0tLQoGg3rxxRdVUVGhQCAwbsuso6NDmzZtUkNDgyZMmGB3nISVl5dH/3nevHkqLi5WYWGhnn/+ea1fv97GZPFFIhEtXLhQjzzyiCRp/vz5OnHihGpra1VRUWFzuqH99re/VXl5+ZDPABtPuCKLg8fRjK2NGzfqlVde0ZtvvqmpU6faHWdIGRkZmjlzphYsWCC/36+ioiI9/vjjdseK69ixYzp79qy+9KUvKT09Xenp6QoEAtqxY4fS09PV399vd8SEZGVlafbs2Wpra7M7Slz5+fmXvKG58cYbx/1HopL0t7/9TYcPH9Z3v/tdu6MMC0UWB4+jGRuWZWnjxo2qq6vTG2+8oenTp9sdaUQikYjC4bDdMeJatmyZjh8/rpaWluhYuHCh1q5dq5aWFqWlpdkdMSG9vb06deqU8vPz7Y4S15IlSy75Cslf//pXFRYW2pQocbt371ZOTo5Wrlxpd5Rh4aPFQZj2OJre3t6Yd6rt7e1qaWlRdna2CgoKbEwWn8/n0759+3TgwAFlZmZG7z+63W5NnDjR5nQDq6qqUnl5uQoKCtTT06N9+/bprbfe0qFDh+yOFldmZuYl9x0nTZqkyZMnj+v7kVu2bNGqVatUWFioM2fOqLq6WmlpaVqzZo3d0eJ64IEH9JWvfEWPPPKI7r77br3zzjvatWuXdu3aZXe0QUUiEe3evVsVFRVKTzesGuyeNjne/frXv7YKCgqsjIwMa/HixVZzc7PdkeJ68803LUmXjIqKCrujxTVQXknW7t277Y4W17333msVFhZaGRkZ1pQpU6xly5ZZr7/+ut2xhs2E6ff33HOPlZ+fb2VkZFif+9znrHvuucdqa2uzO9aQXn75ZWvu3LmW0+m05syZY+3atcvuSEM6dOiQJclqbW21O8qw8RgXAIDRuEcGADAaRQYAMBpFBgAwGkUGADAaRQYAMBpFBgAwGkUGADAaRQYAMBpFBgAwGkUGADAaRQYAMNr/AS1VY1DtJbhWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if your project is still loaded onto the VRAM\n",
    "print(torch.cuda.memory_allocated())\n",
    "# this should return 0 if everything is unloaded\n",
    "print(torch.cuda.memory_reserved())\n",
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "# only 1K datapoints but each points has a lot of data\n",
    "data_name = \"mlabonne/guanaco-llama2-1k\"\n",
    "training_data = load_dataset(data_name, split=\"train\")\n",
    "# check the data\n",
    "print(training_data.shape)\n",
    "# #11 is a QA sample in English\n",
    "print(training_data[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"./results_modified\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=50,\n",
    "    logging_steps=50,\n",
    "    learning_rate=4e-5,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "# LoRA Config\n",
    "# reduce rank r if you're running out of vram\n",
    "peft_parameters = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, peft_parameters)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer with LoRA configuration\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=llama_tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "fine_tuning.model.save_pretrained(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "model = PeftModel.from_pretrained(base_model, new_model_name)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fttenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
