{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune Test \n",
    "Making a test for fine tuning for planning projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this based on the server usage\n",
    "# need to run this first to make sure that it runs on the correct GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/faster2/dc903/CS4RP/fttenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, TrainingArguments, pipeline, BitsAndBytesConfig\n",
    "from huggingface_hub import login, snapshot_download, hf_hub_download\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "import torch.nn as nn\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check VRAM\n",
    "# if not using Cheery, you will need to change this\n",
    "def check_vram():\n",
    "    # Initialize NVIDIA management library\n",
    "    pynvml.nvmlInit()\n",
    "\n",
    "    # Get a handle for each GPU device\n",
    "    handle_list = [pynvml.nvmlDeviceGetHandleByIndex(i) for i in range(pynvml.nvmlDeviceGetCount())]\n",
    "\n",
    "    info_used = []\n",
    "    points = [0,1,2,3,4,5,6,7]\n",
    "    max_vram = 24\n",
    "\n",
    "    # Iterate over all GPU devices and print VRAM usage\n",
    "    for handle in handle_list:\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        info_used.append( (info.used//1024**2)/1000)\n",
    "\n",
    "    print (info_used)\n",
    "\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.ylim(0,max_vram)\n",
    "    plt.bar(points, info_used)\n",
    "    plt.plot()\n",
    "    pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT RUN THIS CODE BLOCK IF 'llama-2-7b-hf' IS IN YOUR DIRECTORY\n",
    "\"\"\"\n",
    "\n",
    "# getting the authorisation from huggingface to use the model (in this case llama 2 7b )\n",
    "access_key = open('hf_ak.txt','r').read()\n",
    "login(token = access_key)\n",
    "\n",
    "# Download model files. If it's in the project directory, there's no need to run this again\n",
    "# use df -H in the terminal to check and see if there's enough space to download the model\n",
    "# this process will take a long time\n",
    "# will save the model in the directory specified\n",
    "model_path = snapshot_download(\"meta-llama/Llama-2-7b-hf\", local_dir=\"./llama-2-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do not run any of this is if llama-2-7b-hf is filled\n",
    "- You'll need to convert them to the huggingface Transformers format using the conversion script `convert_llama_weights_to_hf.py`. \n",
    "- Obviously, hf stands for huggingface. Maybe with the hf version, the conversion wouldn't be needed\n",
    "- to run this, run the following\n",
    "\n",
    "```\n",
    "python convert_llama_weights_to_hf.py \\\n",
    "    --input_dir /llama-2-7b --model_size 7B --output_dir /llama-2-7b-hf\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.079, 5.791, 0.415, 4.677, 0.415, 0.415, 0.418, 0.418]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilization.gpu [%]\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n",
      "0 %\n"
     ]
    }
   ],
   "source": [
    "# each GPU util\n",
    "!nvidia-smi --query-gpu=utilization.gpu --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and tokenizer names\n",
    "base_model_name = \"llama-2-7b-hf\"\n",
    "new_model_name = \"llama-2-7b-enhanced\" #You can give your own name for fine tuned model\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "# resolve device_map_auto issue\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.079, 5.791, 0.415, 4.677, 0.415, 0.415, 13.479, 13.479]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following code if you want to unload the VRAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "# only 1K datapoints but each points has a lot of data\n",
    "data_name = \"mlabonne/guanaco-llama2-1k\"\n",
    "training_data = load_dataset(data_name, split=\"train\")\n",
    "# check the data\n",
    "print(training_data.shape)\n",
    "# #11 is a QA sample in English\n",
    "print(training_data[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"./results_modified\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=50,\n",
    "    logging_steps=50,\n",
    "    learning_rate=4e-5,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "# LoRA Config\n",
    "peft_parameters = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, peft_parameters)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer with LoRA configuration\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=llama_tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "fine_tuning.model.save_pretrained(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "model = PeftModel.from_pretrained(base_model, new_model_name)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fttenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
